{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver  # Used for opening up a web browser\n",
    "from selenium.common.exceptions import NoSuchElementException  # Used for when element not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exit_prompt(driver):\n",
    "    '''\n",
    "    Tries to click out of sign in prompt from glassdoor or the estimated salarty prompt.\n",
    "    Sign in prompt does not trigger when page loads, only after a job posting is clicked (does not appear again after clicking X).\n",
    "    Glassdoor estimated salary pop up also appears occasionally when progressing through job postings.\n",
    "    '''\n",
    "    try:\n",
    "        exit = driver.find_element_by_class_name('modal_closeIcon')\n",
    "        exit.click()\n",
    "    except NoSuchElementException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_page(driver, page_num):\n",
    "    '''\n",
    "    Concatenates string argument for clicking on next page and clicks on next page element\n",
    "    '''\n",
    "    page_element = '//div[@class=\"pageContainer\"]/button[@data-test=\"pagination-link-'\n",
    "    page_element += str(page_num) + '\\\"' + ']'\n",
    "    try:\n",
    "        driver.find_element_by_xpath(page_element).click()\n",
    "    except NoSuchElementException:\n",
    "        print('No Page Element Found')\n",
    "    time.sleep(3)  # Wait for page to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(rows, test=False):\n",
    "    '''\n",
    "    Grabs rows of data including:\n",
    "        - Job name, company name, and job location\n",
    "        - Job salary and company rating\n",
    "        - Company information\n",
    "    '''\n",
    "    url = 'https://www.glassdoor.com/Job/data-scientist-jobs-SRCH_KO0,14.htm'\n",
    "    driver = webdriver.Edge()  # Using Edge browser\n",
    "    driver.get(url)\n",
    "    all_jobs = []\n",
    "    # job_count = 1\n",
    "    job_element_count = 0\n",
    "    page_num_element = 1\n",
    "    # job_posts = driver.find_elements_by_class_name('react-job-listing')\n",
    "\n",
    "    while len(all_jobs) <= rows:  # If less than specified rows.\n",
    "        company_name = ''\n",
    "        job_name = ''\n",
    "        location = ''\n",
    "        job_desc = ''\n",
    "        salary = ''\n",
    "        rating = ''\n",
    "        company_size = ''\n",
    "        company_type = ''\n",
    "        company_sector = ''\n",
    "        year_founded = ''\n",
    "        company_industry = ''\n",
    "        company_revenue = ''\n",
    "        job_posts = driver.find_elements_by_class_name('react-job-listing')  # To prevent element refresh, page document missing\n",
    "        exit_prompt(driver)  # Start of new page pop up...\n",
    "        job_posts[job_element_count].click()\n",
    "        time.sleep(2)  # Wait to prevent bot detection \n",
    "        exit_prompt(driver)  # If estimated salary prompt -> problem right now is if you exit the prompt, you re-read the same job. This is because the prompt pops up, but you don't move onto the next job yet...\n",
    "\n",
    "        try:  # Attempt at acquiring information\n",
    "            # Basic Job Information\n",
    "            company_name = driver.find_element_by_class_name('css-xuk5ye').text.split('\\n')[0]\n",
    "            job_name = driver.find_element_by_class_name('css-1j389vi').text\n",
    "            location = driver.find_element_by_class_name('css-56kyx5').text\n",
    "            driver.find_element_by_class_name('css-t3xrds').click()\n",
    "            job_desc = driver.find_element_by_class_name('jobDescriptionContent').text\n",
    "\n",
    "            # Salary and Company Rating\n",
    "            try:  # If salary estimate exists\n",
    "                salary = driver.find_element_by_class_name('css-1hbqxax').text\n",
    "            except NoSuchElementException:\n",
    "                salary = -1\n",
    "            try:  # If rating exists\n",
    "                rating = driver.find_element_by_class_name('css-ey2fjr').text\n",
    "            except:\n",
    "                rating = -1\n",
    "\n",
    "            # Company Information\n",
    "            try: # Separate try except for each company info, or else all will default to -1 if even one piece of information is missing.\n",
    "                company_size = driver.find_element_by_xpath('//div[@id=\"EmpBasicInfo\"]/div[1]/div/div[1]/span[2]').text\n",
    "            except NoSuchElementException:\n",
    "                company_size = -1\n",
    "            try:\n",
    "                company_type = driver.find_element_by_xpath('//div[@id=\"EmpBasicInfo\"]/div[1]/div/div[3]/span[2]').text\n",
    "            except NoSuchElementException:\n",
    "                company_size = -1\n",
    "            try:\n",
    "                company_sector = driver.find_element_by_xpath('//div[@id=\"EmpBasicInfo\"]/div[1]/div/div[5]/span[2]').text\n",
    "            except NoSuchElementException:\n",
    "                company_size = -1\n",
    "            try:\n",
    "                year_founded = driver.find_element_by_xpath('//div[@id=\"EmpBasicInfo\"]/div[1]/div/div[2]/span[2]').text\n",
    "            except NoSuchElementException:\n",
    "                company_size = -1\n",
    "            try:\n",
    "                company_industry = driver.find_element_by_xpath('//div[@id=\"EmpBasicInfo\"]/div[1]/div/div[4]/span[2]').text\n",
    "            except NoSuchElementException:\n",
    "                company_size = -1\n",
    "            try:\n",
    "                company_revenue = driver.find_element_by_xpath('//div[@id=\"EmpBasicInfo\"]/div[1]/div/div[6]/span[2]').text\n",
    "            except NoSuchElementException:\n",
    "                company_size = -1\n",
    "            all_jobs.append([company_name, job_name, location, job_desc, salary, rating, company_size, company_type, company_sector, year_founded,company_industry, company_revenue])\n",
    "            if test:  # If testing, then print outputs\n",
    "                print('Company Name: ', company_name)\n",
    "                print('Job Name: ', job_name)\n",
    "                print('Location: ', location)\n",
    "                print('Job Description: ', job_desc[:20])\n",
    "                print('Salary:', salary)\n",
    "                print('Rating:' , rating)\n",
    "                print('Company Size: ', company_size)\n",
    "                print('Company Type: ', company_type)\n",
    "                print('Company Sector: ', company_sector)\n",
    "                print('Year Founded: ', year_founded)\n",
    "                print('Company Industry: ', company_industry)\n",
    "                print('Company Revenue: ', company_revenue)\n",
    "                print('\\n')\n",
    "\n",
    "\n",
    "        except:\n",
    "            time.sleep(4)\n",
    "        \n",
    "        if job_element_count == 29:  # If last job on page, move to next page\n",
    "            job_element_count = -1\n",
    "            page_num_element += 1\n",
    "            print('Page: ', page_num_element)\n",
    "            # print('Reached last job on the page')\n",
    "            try:  # In case page fails to load, return data collected.\n",
    "                get_next_page(driver, page_num_element)\n",
    "            except:\n",
    "                return all_jobs \n",
    "        else:  # Do not reset counters yet\n",
    "            pass\n",
    "        job_element_count += 1\n",
    "        # job_count += 1\n",
    "\n",
    "    print(\"Exit While Loop\")\n",
    "    return all_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run times for fun:\n",
    "    # May 1st: 38 minutes, 58.4 seconds\n",
    "    # May 2nd: 38 minutes, 42.4 seconds\n",
    "    # May 3rd, 39 minutes, 38.7 seconds\n",
    "    # May 4th, 38 minutes, 59.8 seconds\n",
    "    # May 5th, 39 minutes, 2.4 seconds\n",
    "    # May 6th, 38 minutes, 52.1 seconds\n",
    "    # May 7th, 38 minutes 45.2 seconds\n",
    "    # May 8th, 38 minutes, 47.1 seconds\n",
    "    # May 9th, 39 minutes, 37.6 seconds\n",
    "    # May 10th, 40 minutes, 9.1 seconds\n",
    "    # May 11th, 38 minutes, 59.9 seconds\n",
    "    # May 12th, 41 minutes, 22.8 seconds\n",
    "    # May 13th, 38 minutes, 38.3 seconds\n",
    "    # May 14th, 39 minutes, 37.9 seconds\n",
    "    # May 15th, 39 minutes, 40.9 seconds\n",
    "    # May 16th, 39 minutes, 14.5 seconds\n",
    "    # May 17th, 39 minutes, 25.6 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_df_csv(date):\n",
    "    '''\n",
    "    Converts scraped data to Pandas DataFrame.\n",
    "    '''\n",
    "    data = get_data(850, test=False)\n",
    "    df = pd.DataFrame(data=data, columns=['Company Name', 'Job Name', 'Job Location', 'Job Description', 'Salary', 'Rating', 'Company Size', 'Company Type', 'Company Sector', 'Year Founded', 'Company Industry', 'Company Revenue'])\n",
    "    df = df.drop_duplicates()\n",
    "    file_name = date + '_data.csv'\n",
    "    df.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_all_csv():\n",
    "    '''\n",
    "    Loads all CSV data files and concatenates all data into a single DataFrame. Then eliminates duplicated job rows and merges into a single file.\n",
    "    '''\n",
    "    directory = os.getcwd()\n",
    "    empty = pd.DataFrame()\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith('.csv') and file != 'cleaned_data.csv' and file != 'temp_all.csv':\n",
    "            print(file)\n",
    "            empty = pd.concat([empty, pd.read_csv(file)], axis=0)\n",
    "        else:\n",
    "            pass\n",
    "    empty = empty.drop_duplicates()\n",
    "    print('Unique Jobs: ', len(empty))\n",
    "    return empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_to_df_csv('may_1_2022')\n",
    "# data_to_df_csv('may_2_2022')\n",
    "# data_to_df_csv('may_3_2022')\n",
    "# data_to_df_csv('may_5_2022')\n",
    "# data_to_df_csv('may_6_2022')\n",
    "# data_to_df_csv('may_7_2022')\n",
    "# data_to_df_csv('may_8_2022')\n",
    "# data_to_df_csv('may_9_2022')\n",
    "# data_to_df_csv('may_10_2022')\n",
    "# data_to_df_csv('may_11_2022')\n",
    "# data_to_df_csv('may_12_2022')\n",
    "# data_to_df_csv('may_13_2022')\n",
    "# data_to_df_csv('may_14_2022')\n",
    "# data_to_df_csv('may_15_2022')\n",
    "# data_to_df_csv('may_16_2022')\n",
    "# data_to_df_csv('may_17_2022')\n",
    "# data_to_df_csv('may_25_2022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glassdoor_jobs.csv\n",
      "may_10_2022_data.csv\n",
      "may_11_2022_data.csv\n",
      "may_12_2022_data.csv\n",
      "may_13_2022_data.csv\n",
      "may_14_2022_data.csv\n",
      "may_15_2022_data.csv\n",
      "may_16_2022_data.csv\n",
      "may_17_2022_data.csv\n",
      "may_1_2022_data.csv\n",
      "may_25_2022_data.csv\n",
      "may_2_2022_data.csv\n",
      "may_3_2022_data.csv\n",
      "may_5_2022_data.csv\n",
      "may_6_2022_data.csv\n",
      "may_7_2022_data.csv\n",
      "may_8_2022_data.csv\n",
      "may_9_2022_data.csv\n",
      "Unique Jobs:  4892\n"
     ]
    }
   ],
   "source": [
    "overall = concat_all_csv()\n",
    "overall.to_csv('temp_all.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7275b9e9e1a6f54fdb2e1db809ca4f3c4c62f89c8a86e03d52145ea966ecb8e9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('web-scraping')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
