{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver  # Used for opening up a web browser\n",
    "from selenium.common.exceptions import NoSuchElementException  # Used for when element not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exit_prompt(driver):\n",
    "    '''\n",
    "    Tries to click out of sign in prompt from glassdoor or the estimated salarty prompt.\n",
    "    Sign in prompt does not trigger when page loads, only after a job posting is clicked (does not appear again after clicking X).\n",
    "    Glassdoor estimated salary pop up also appears occasionally when progressing through job postings.\n",
    "    '''\n",
    "    try:\n",
    "        exit = driver.find_element_by_class_name('modal_closeIcon')\n",
    "        exit.click()\n",
    "    except NoSuchElementException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_page(driver, page_num):\n",
    "    '''\n",
    "    Concatenates string argument for clicking on next page and clicks on next page element\n",
    "    '''\n",
    "    page_element = '//div[@class=\"pageContainer\"]/button[@data-test=\"pagination-link-'\n",
    "    page_element += str(page_num) + '\\\"' + ']'\n",
    "    try:\n",
    "        driver.find_element_by_xpath(page_element).click()\n",
    "    except NoSuchElementException:\n",
    "        print('No Page Element Found')\n",
    "    time.sleep(3)  # Wait for page to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(rows, test=False):\n",
    "    '''\n",
    "    Grabs rows of data including:\n",
    "        - Job name, company name, and job location\n",
    "        - Job salary and company rating\n",
    "        - Company information\n",
    "    '''\n",
    "    url = 'https://www.glassdoor.com/Job/data-scientist-jobs-SRCH_KO0,14.htm'\n",
    "    driver = webdriver.Edge()  # Using Edge browser\n",
    "    driver.get(url)\n",
    "    all_jobs = []\n",
    "    # job_count = 1\n",
    "    job_element_count = 0\n",
    "    page_num_element = 1\n",
    "    # job_posts = driver.find_elements_by_class_name('react-job-listing')\n",
    "\n",
    "    while len(all_jobs) <= rows:  # If less than specified rows.\n",
    "        company_name = ''\n",
    "        job_name = ''\n",
    "        location = ''\n",
    "        job_desc = ''\n",
    "        salary = ''\n",
    "        rating = ''\n",
    "        company_size = ''\n",
    "        company_type = ''\n",
    "        company_sector = ''\n",
    "        year_founded = ''\n",
    "        company_industry = ''\n",
    "        company_revenue = ''\n",
    "        job_posts = driver.find_elements_by_class_name('react-job-listing')  # To prevent element refresh, page document missing\n",
    "        exit_prompt(driver)  # Start of new page pop up...\n",
    "        job_posts[job_element_count].click()\n",
    "        time.sleep(2)  # Wait to prevent bot detection \n",
    "        exit_prompt(driver)  # If estimated salary prompt -> problem right now is if you exit the prompt, you re-read the same job. This is because the prompt pops up, but you don't move onto the next job yet...\n",
    "\n",
    "        try:  # Attempt at acquiring information\n",
    "            # Basic Job Information\n",
    "            company_name = driver.find_element_by_class_name('css-xuk5ye').text.split('\\n')[0]\n",
    "            job_name = driver.find_element_by_class_name('css-1j389vi').text\n",
    "            location = driver.find_element_by_class_name('css-56kyx5').text\n",
    "            driver.find_element_by_class_name('css-t3xrds').click()\n",
    "            job_desc = driver.find_element_by_class_name('jobDescriptionContent').text\n",
    "\n",
    "            # Salary and Company Rating\n",
    "            try:  # If salary estimate exists\n",
    "                salary = driver.find_element_by_class_name('css-1hbqxax').text\n",
    "            except NoSuchElementException:\n",
    "                salary = -1\n",
    "            try:  # If rating exists\n",
    "                rating = driver.find_element_by_class_name('css-ey2fjr').text\n",
    "            except:\n",
    "                rating = -1\n",
    "\n",
    "            # Company Information\n",
    "            try: # Separate try except for each company info, or else all will default to -1 if even one piece of information is missing.\n",
    "                company_size = driver.find_element_by_xpath('//div[@id=\"EmpBasicInfo\"]/div[1]/div/div[1]/span[2]').text\n",
    "            except NoSuchElementException:\n",
    "                company_size = -1\n",
    "            try:\n",
    "                company_type = driver.find_element_by_xpath('//div[@id=\"EmpBasicInfo\"]/div[1]/div/div[3]/span[2]').text\n",
    "            except NoSuchElementException:\n",
    "                company_size = -1\n",
    "            try:\n",
    "                company_sector = driver.find_element_by_xpath('//div[@id=\"EmpBasicInfo\"]/div[1]/div/div[5]/span[2]').text\n",
    "            except NoSuchElementException:\n",
    "                company_size = -1\n",
    "            try:\n",
    "                year_founded = driver.find_element_by_xpath('//div[@id=\"EmpBasicInfo\"]/div[1]/div/div[2]/span[2]').text\n",
    "            except NoSuchElementException:\n",
    "                company_size = -1\n",
    "            try:\n",
    "                company_industry = driver.find_element_by_xpath('//div[@id=\"EmpBasicInfo\"]/div[1]/div/div[4]/span[2]').text\n",
    "            except NoSuchElementException:\n",
    "                company_size = -1\n",
    "            try:\n",
    "                company_revenue = driver.find_element_by_xpath('//div[@id=\"EmpBasicInfo\"]/div[1]/div/div[6]/span[2]').text\n",
    "            except NoSuchElementException:\n",
    "                company_size = -1\n",
    "            all_jobs.append([company_name, job_name, location, job_desc, salary, rating, company_size, company_type, company_sector, year_founded,company_industry, company_revenue])\n",
    "            if test:  # If testing, then print outputs\n",
    "                print('Company Name: ', company_name)\n",
    "                print('Job Name: ', job_name)\n",
    "                print('Location: ', location)\n",
    "                print('Job Description: ', job_desc[:20])\n",
    "                print('Salary:', salary)\n",
    "                print('Rating:' , rating)\n",
    "                print('Company Size: ', company_size)\n",
    "                print('Company Type: ', company_type)\n",
    "                print('Company Sector: ', company_sector)\n",
    "                print('Year Founded: ', year_founded)\n",
    "                print('Company Industry: ', company_industry)\n",
    "                print('Company Revenue: ', company_revenue)\n",
    "                print('\\n')\n",
    "\n",
    "\n",
    "        except:\n",
    "            time.sleep(4)\n",
    "        \n",
    "        if job_element_count == 29:  # If last job on page, move to next page\n",
    "            job_element_count = -1\n",
    "            page_num_element += 1\n",
    "            print('Page: ', page_num_element)\n",
    "            # print('Reached last job on the page')\n",
    "            try:  # In case page fails to load, return data collected.\n",
    "                get_next_page(driver, page_num_element)\n",
    "            except:\n",
    "                return all_jobs \n",
    "        else:  # Do not reset counters yet\n",
    "            pass\n",
    "        job_element_count += 1\n",
    "        # job_count += 1\n",
    "\n",
    "    print(\"Exit While Loop\")\n",
    "    return all_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run times for fun:\n",
    "    # May 1st: 38 minutes, 58.4 seconds\n",
    "    # May 2nd: 38 minutes, 42.4 seconds\n",
    "    # May 3rd, 39 minutes, 38.7 seconds\n",
    "    # May 4th, 38 minutes, 59.8 seconds\n",
    "    # May 5th, 39 minutes, 2.4 seconds\n",
    "    # May 6th, 38 minutes, 52.1 seconds\n",
    "    # May 7th, 38 minutes 45.2 seconds\n",
    "    # May 8th, 38 minutes, 47.1 seconds\n",
    "    # May 9th, 39 minutes, 37.6 seconds\n",
    "    # May 10th, 40 minutes, 9.1 seconds\n",
    "    # May 11th, 38 minutes, 59.9 seconds\n",
    "    # May 12th, 41 minutes, 22.8 seconds\n",
    "    # May 13th, 38 minutes, 38.3 seconds\n",
    "    # May 14th, 39 minutes, 37.9 seconds\n",
    "    # May 15th, 39 minutes, 40.9 seconds\n",
    "    # May 16th, 39 minutes, 14.5 seconds\n",
    "    # May 17th, 39 minutes, 25.6 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_df_csv(date):\n",
    "    '''\n",
    "    Converts scraped data to Pandas DataFrame.\n",
    "    '''\n",
    "    data = get_data(850, test=False)\n",
    "    df = pd.DataFrame(data=data, columns=['Company Name', 'Job Name', 'Job Location', 'Job Description', 'Salary', 'Rating', 'Company Size', 'Company Type', 'Company Sector', 'Year Founded', 'Company Industry', 'Company Revenue'])\n",
    "    df = df.drop_duplicates()\n",
    "    file_name = date + '_data.csv'\n",
    "    df.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_all_csv():\n",
    "    '''\n",
    "    Loads all CSV data files and concatenates all data into a single DataFrame. Then eliminates duplicated job rows and merges into a single file.\n",
    "    '''\n",
    "    directory = os.getcwd()\n",
    "    empty = pd.DataFrame()\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith('.csv') and file != 'cleaned_data.csv' and file != 'temp_all.csv':\n",
    "            print(file)\n",
    "            empty = pd.concat([empty, pd.read_csv(file)], axis=0)\n",
    "        else:\n",
    "            pass\n",
    "    empty = empty.drop_duplicates()\n",
    "    print('Unique Jobs: ', len(empty))\n",
    "    return empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_to_df_csv('may_1_2022')\n",
    "# data_to_df_csv('may_2_2022')\n",
    "# data_to_df_csv('may_3_2022')\n",
    "# data_to_df_csv('may_5_2022')\n",
    "# data_to_df_csv('may_6_2022')\n",
    "# data_to_df_csv('may_7_2022')\n",
    "# data_to_df_csv('may_8_2022')\n",
    "# data_to_df_csv('may_9_2022')\n",
    "# data_to_df_csv('may_10_2022')\n",
    "# data_to_df_csv('may_11_2022')\n",
    "# data_to_df_csv('may_12_2022')\n",
    "# data_to_df_csv('may_13_2022')\n",
    "# data_to_df_csv('may_14_2022')\n",
    "# data_to_df_csv('may_15_2022')\n",
    "# data_to_df_csv('may_16_2022')\n",
    "# data_to_df_csv('may_17_2022')\n",
    "# data_to_df_csv('may_25_2022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SessionNotCreatedException",
     "evalue": "Message: session not created: This version of MSEdgeDriver only supports MSEdge version 100\nCurrent browser version is 102.0.1245.33 with binary path C:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSessionNotCreatedException\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;32md:\\Documents\\JupyterNotebooks\\Projects\\Glassdoor Webscraping\\raw_data_and_py_files\\web_scrape.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Documents/JupyterNotebooks/Projects/Glassdoor%20Webscraping/raw_data_and_py_files/web_scrape.ipynb#ch0000009?line=0'>1</a>\u001b[0m data_to_df_csv(\u001b[39m'\u001b[39;49m\u001b[39mjun_4_2022\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32md:\\Documents\\JupyterNotebooks\\Projects\\Glassdoor Webscraping\\raw_data_and_py_files\\web_scrape.ipynb Cell 6'\u001b[0m in \u001b[0;36mdata_to_df_csv\u001b[1;34m(date)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/JupyterNotebooks/Projects/Glassdoor%20Webscraping/raw_data_and_py_files/web_scrape.ipynb#ch0000005?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdata_to_df_csv\u001b[39m(date):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/JupyterNotebooks/Projects/Glassdoor%20Webscraping/raw_data_and_py_files/web_scrape.ipynb#ch0000005?line=1'>2</a>\u001b[0m     \u001b[39m'''\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/JupyterNotebooks/Projects/Glassdoor%20Webscraping/raw_data_and_py_files/web_scrape.ipynb#ch0000005?line=2'>3</a>\u001b[0m \u001b[39m    Converts scraped data to Pandas DataFrame.\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/JupyterNotebooks/Projects/Glassdoor%20Webscraping/raw_data_and_py_files/web_scrape.ipynb#ch0000005?line=3'>4</a>\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Documents/JupyterNotebooks/Projects/Glassdoor%20Webscraping/raw_data_and_py_files/web_scrape.ipynb#ch0000005?line=4'>5</a>\u001b[0m     data \u001b[39m=\u001b[39m get_data(\u001b[39m850\u001b[39;49m, test\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/JupyterNotebooks/Projects/Glassdoor%20Webscraping/raw_data_and_py_files/web_scrape.ipynb#ch0000005?line=5'>6</a>\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data\u001b[39m=\u001b[39mdata, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mCompany Name\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mJob Name\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mJob Location\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mJob Description\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSalary\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mRating\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCompany Size\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCompany Type\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCompany Sector\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mYear Founded\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCompany Industry\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCompany Revenue\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/JupyterNotebooks/Projects/Glassdoor%20Webscraping/raw_data_and_py_files/web_scrape.ipynb#ch0000005?line=6'>7</a>\u001b[0m     df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mdrop_duplicates()\n",
      "\u001b[1;32md:\\Documents\\JupyterNotebooks\\Projects\\Glassdoor Webscraping\\raw_data_and_py_files\\web_scrape.ipynb Cell 4'\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(rows, test)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/JupyterNotebooks/Projects/Glassdoor%20Webscraping/raw_data_and_py_files/web_scrape.ipynb#ch0000003?line=1'>2</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/JupyterNotebooks/Projects/Glassdoor%20Webscraping/raw_data_and_py_files/web_scrape.ipynb#ch0000003?line=2'>3</a>\u001b[0m \u001b[39mGrabs rows of data including:\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/JupyterNotebooks/Projects/Glassdoor%20Webscraping/raw_data_and_py_files/web_scrape.ipynb#ch0000003?line=3'>4</a>\u001b[0m \u001b[39m    - Job name, company name, and job location\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/JupyterNotebooks/Projects/Glassdoor%20Webscraping/raw_data_and_py_files/web_scrape.ipynb#ch0000003?line=4'>5</a>\u001b[0m \u001b[39m    - Job salary and company rating\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/JupyterNotebooks/Projects/Glassdoor%20Webscraping/raw_data_and_py_files/web_scrape.ipynb#ch0000003?line=5'>6</a>\u001b[0m \u001b[39m    - Company information\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/JupyterNotebooks/Projects/Glassdoor%20Webscraping/raw_data_and_py_files/web_scrape.ipynb#ch0000003?line=6'>7</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/JupyterNotebooks/Projects/Glassdoor%20Webscraping/raw_data_and_py_files/web_scrape.ipynb#ch0000003?line=7'>8</a>\u001b[0m url \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhttps://www.glassdoor.com/Job/data-scientist-jobs-SRCH_KO0,14.htm\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Documents/JupyterNotebooks/Projects/Glassdoor%20Webscraping/raw_data_and_py_files/web_scrape.ipynb#ch0000003?line=8'>9</a>\u001b[0m driver \u001b[39m=\u001b[39m webdriver\u001b[39m.\u001b[39;49mEdge()  \u001b[39m# Using Edge browser\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/JupyterNotebooks/Projects/Glassdoor%20Webscraping/raw_data_and_py_files/web_scrape.ipynb#ch0000003?line=9'>10</a>\u001b[0m driver\u001b[39m.\u001b[39mget(url)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/JupyterNotebooks/Projects/Glassdoor%20Webscraping/raw_data_and_py_files/web_scrape.ipynb#ch0000003?line=10'>11</a>\u001b[0m all_jobs \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda\\envs\\web-scraping\\lib\\site-packages\\selenium\\webdriver\\edge\\webdriver.py:61\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[1;34m(self, executable_path, capabilities, port, verbose, service_log_path, log_path, keep_alive)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/ProgramData/Anaconda/envs/web-scraping/lib/site-packages/selenium/webdriver/edge/webdriver.py?line=57'>58</a>\u001b[0m \u001b[39mif\u001b[39;00m capabilities \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/ProgramData/Anaconda/envs/web-scraping/lib/site-packages/selenium/webdriver/edge/webdriver.py?line=58'>59</a>\u001b[0m     capabilities \u001b[39m=\u001b[39m DesiredCapabilities\u001b[39m.\u001b[39mEDGE\n\u001b[1;32m---> <a href='file:///c%3A/ProgramData/Anaconda/envs/web-scraping/lib/site-packages/selenium/webdriver/edge/webdriver.py?line=60'>61</a>\u001b[0m RemoteWebDriver\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m     <a href='file:///c%3A/ProgramData/Anaconda/envs/web-scraping/lib/site-packages/selenium/webdriver/edge/webdriver.py?line=61'>62</a>\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m     <a href='file:///c%3A/ProgramData/Anaconda/envs/web-scraping/lib/site-packages/selenium/webdriver/edge/webdriver.py?line=62'>63</a>\u001b[0m     command_executor\u001b[39m=\u001b[39;49mRemoteConnection(\u001b[39m'\u001b[39;49m\u001b[39mhttp://localhost:\u001b[39;49m\u001b[39m%d\u001b[39;49;00m\u001b[39m'\u001b[39;49m \u001b[39m%\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport,\n\u001b[0;32m     <a href='file:///c%3A/ProgramData/Anaconda/envs/web-scraping/lib/site-packages/selenium/webdriver/edge/webdriver.py?line=63'>64</a>\u001b[0m                                       resolve_ip\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     <a href='file:///c%3A/ProgramData/Anaconda/envs/web-scraping/lib/site-packages/selenium/webdriver/edge/webdriver.py?line=64'>65</a>\u001b[0m                                       keep_alive\u001b[39m=\u001b[39;49mkeep_alive),\n\u001b[0;32m     <a href='file:///c%3A/ProgramData/Anaconda/envs/web-scraping/lib/site-packages/selenium/webdriver/edge/webdriver.py?line=65'>66</a>\u001b[0m     desired_capabilities\u001b[39m=\u001b[39;49mcapabilities)\n\u001b[0;32m     <a href='file:///c%3A/ProgramData/Anaconda/envs/web-scraping/lib/site-packages/selenium/webdriver/edge/webdriver.py?line=66'>67</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_remote \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda\\envs\\web-scraping\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:157\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[1;34m(self, command_executor, desired_capabilities, browser_profile, proxy, keep_alive, file_detector, options)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda/envs/web-scraping/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=153'>154</a>\u001b[0m \u001b[39mif\u001b[39;00m browser_profile \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda/envs/web-scraping/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=154'>155</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mPlease use FirefoxOptions to set browser profile\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda/envs/web-scraping/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=155'>156</a>\u001b[0m                   \u001b[39mDeprecationWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m--> <a href='file:///c%3A/ProgramData/Anaconda/envs/web-scraping/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=156'>157</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstart_session(capabilities, browser_profile)\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda/envs/web-scraping/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=157'>158</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to \u001b[39m=\u001b[39m SwitchTo(\u001b[39mself\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda/envs/web-scraping/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=158'>159</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mobile \u001b[39m=\u001b[39m Mobile(\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda\\envs\\web-scraping\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:252\u001b[0m, in \u001b[0;36mWebDriver.start_session\u001b[1;34m(self, capabilities, browser_profile)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda/envs/web-scraping/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=248'>249</a>\u001b[0m w3c_caps \u001b[39m=\u001b[39m _make_w3c_caps(capabilities)\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda/envs/web-scraping/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=249'>250</a>\u001b[0m parameters \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mcapabilities\u001b[39m\u001b[39m\"\u001b[39m: w3c_caps,\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda/envs/web-scraping/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=250'>251</a>\u001b[0m               \u001b[39m\"\u001b[39m\u001b[39mdesiredCapabilities\u001b[39m\u001b[39m\"\u001b[39m: capabilities}\n\u001b[1;32m--> <a href='file:///c%3A/ProgramData/Anaconda/envs/web-scraping/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=251'>252</a>\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(Command\u001b[39m.\u001b[39;49mNEW_SESSION, parameters)\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda/envs/web-scraping/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=252'>253</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39msessionId\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m response:\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda/envs/web-scraping/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=253'>254</a>\u001b[0m     response \u001b[39m=\u001b[39m response[\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda\\envs\\web-scraping\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:321\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda/envs/web-scraping/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=318'>319</a>\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_executor\u001b[39m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda/envs/web-scraping/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=319'>320</a>\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[1;32m--> <a href='file:///c%3A/ProgramData/Anaconda/envs/web-scraping/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=320'>321</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_handler\u001b[39m.\u001b[39;49mcheck_response(response)\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda/envs/web-scraping/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=321'>322</a>\u001b[0m     response[\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda/envs/web-scraping/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=322'>323</a>\u001b[0m         response\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda/envs/web-scraping/lib/site-packages/selenium/webdriver/remote/webdriver.py?line=323'>324</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda\\envs\\web-scraping\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:242\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda/envs/web-scraping/lib/site-packages/selenium/webdriver/remote/errorhandler.py?line=239'>240</a>\u001b[0m         alert_text \u001b[39m=\u001b[39m value[\u001b[39m'\u001b[39m\u001b[39malert\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda/envs/web-scraping/lib/site-packages/selenium/webdriver/remote/errorhandler.py?line=240'>241</a>\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)\n\u001b[1;32m--> <a href='file:///c%3A/ProgramData/Anaconda/envs/web-scraping/lib/site-packages/selenium/webdriver/remote/errorhandler.py?line=241'>242</a>\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mSessionNotCreatedException\u001b[0m: Message: session not created: This version of MSEdgeDriver only supports MSEdge version 100\nCurrent browser version is 102.0.1245.33 with binary path C:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe\n"
     ]
    }
   ],
   "source": [
    "data_to_df_csv('jun_4_2022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall = concat_all_csv()\n",
    "overall.to_csv('data/temp_all.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7275b9e9e1a6f54fdb2e1db809ca4f3c4c62f89c8a86e03d52145ea966ecb8e9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('web-scraping')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
